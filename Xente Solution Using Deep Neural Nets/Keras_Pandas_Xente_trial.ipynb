{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xente Solution\n",
    "\n",
    "In this notebook I have somethings I want to try out.\n",
    "\n",
    "- The keras-pandas library: this is a library that helps in data preparation, the data once done, its ready to be used in a normal Machine Learning algorith or it can be used in a neural net.\n",
    "\n",
    "I want to test this today and I see how it stacks up on the leader board, that is the score on the neural net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#lets import the modules we are going to work with\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras_pandas import lib\n",
    "from keras_pandas.Automater import Automater\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's read in the data\n",
    "train = pd.read_csv('training.csv',parse_dates=['TransactionStartTime'])\n",
    "test = pd.read_csv('test.csv',parse_dates=['TransactionStartTime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95662 entries, 0 to 95661\n",
      "Data columns (total 16 columns):\n",
      "TransactionId           95662 non-null object\n",
      "BatchId                 95662 non-null object\n",
      "AccountId               95662 non-null object\n",
      "SubscriptionId          95662 non-null object\n",
      "CustomerId              95662 non-null object\n",
      "CurrencyCode            95662 non-null object\n",
      "CountryCode             95662 non-null int64\n",
      "ProviderId              95662 non-null object\n",
      "ProductId               95662 non-null object\n",
      "ProductCategory         95662 non-null object\n",
      "ChannelId               95662 non-null object\n",
      "Amount                  95662 non-null float64\n",
      "Value                   95662 non-null int64\n",
      "TransactionStartTime    95662 non-null datetime64[ns]\n",
      "PricingStrategy         95662 non-null int64\n",
      "FraudResult             95662 non-null int64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(4), object(10)\n",
      "memory usage: 11.7+ MB\n"
     ]
    }
   ],
   "source": [
    "#let see the data we are looking at, specifically the data types\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((95662, 16), (45019, 15))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we have some object variables and numerical\n",
    "#how big is our dataset\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are some columns we don't need ie transaction id for both datasets\n",
    "fin_id = test['TransactionId'].values\n",
    "test.drop(columns=['TransactionId','CurrencyCode','CountryCode','Amount'],inplace=True)\n",
    "train.drop(columns=['TransactionId','CurrencyCode','CountryCode','Amount'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob_col = [col for col in train.columns if train[col].dtype=='object']\n",
    "num_col = [col for col in train.columns if train[col].dtype!='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Value', 'TransactionStartTime', 'PricingStrategy', 'FraudResult']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Train /test split\n",
    "x_train_, x_test_ = train_test_split(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BatchId</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>SubscriptionId</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>ProviderId</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>ProductCategory</th>\n",
       "      <th>ChannelId</th>\n",
       "      <th>Value</th>\n",
       "      <th>TransactionStartTime</th>\n",
       "      <th>PricingStrategy</th>\n",
       "      <th>FraudResult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41492</th>\n",
       "      <td>BatchId_96402</td>\n",
       "      <td>AccountId_4269</td>\n",
       "      <td>SubscriptionId_1764</td>\n",
       "      <td>CustomerId_4722</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_3</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>1000</td>\n",
       "      <td>2018-12-26 18:45:43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4676</th>\n",
       "      <td>BatchId_97058</td>\n",
       "      <td>AccountId_1591</td>\n",
       "      <td>SubscriptionId_1570</td>\n",
       "      <td>CustomerId_1969</td>\n",
       "      <td>ProviderId_6</td>\n",
       "      <td>ProductId_3</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>1000</td>\n",
       "      <td>2018-11-20 18:11:54</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92856</th>\n",
       "      <td>BatchId_20780</td>\n",
       "      <td>AccountId_3562</td>\n",
       "      <td>SubscriptionId_3768</td>\n",
       "      <td>CustomerId_4000</td>\n",
       "      <td>ProviderId_3</td>\n",
       "      <td>ProductId_3</td>\n",
       "      <td>airtime</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019-02-10 18:34:25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35109</th>\n",
       "      <td>BatchId_125233</td>\n",
       "      <td>AccountId_1115</td>\n",
       "      <td>SubscriptionId_4264</td>\n",
       "      <td>CustomerId_1472</td>\n",
       "      <td>ProviderId_1</td>\n",
       "      <td>ProductId_15</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_3</td>\n",
       "      <td>5000</td>\n",
       "      <td>2018-12-21 09:44:43</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20345</th>\n",
       "      <td>BatchId_135431</td>\n",
       "      <td>AccountId_4841</td>\n",
       "      <td>SubscriptionId_3829</td>\n",
       "      <td>CustomerId_4518</td>\n",
       "      <td>ProviderId_4</td>\n",
       "      <td>ProductId_6</td>\n",
       "      <td>financial_services</td>\n",
       "      <td>ChannelId_2</td>\n",
       "      <td>50</td>\n",
       "      <td>2018-12-07 18:01:28</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              BatchId       AccountId       SubscriptionId       CustomerId  \\\n",
       "41492   BatchId_96402  AccountId_4269  SubscriptionId_1764  CustomerId_4722   \n",
       "4676    BatchId_97058  AccountId_1591  SubscriptionId_1570  CustomerId_1969   \n",
       "92856   BatchId_20780  AccountId_3562  SubscriptionId_3768  CustomerId_4000   \n",
       "35109  BatchId_125233  AccountId_1115  SubscriptionId_4264  CustomerId_1472   \n",
       "20345  BatchId_135431  AccountId_4841  SubscriptionId_3829  CustomerId_4518   \n",
       "\n",
       "         ProviderId     ProductId     ProductCategory    ChannelId  Value  \\\n",
       "41492  ProviderId_6   ProductId_3             airtime  ChannelId_3   1000   \n",
       "4676   ProviderId_6   ProductId_3             airtime  ChannelId_3   1000   \n",
       "92856  ProviderId_3   ProductId_3             airtime  ChannelId_3   2000   \n",
       "35109  ProviderId_1  ProductId_15  financial_services  ChannelId_3   5000   \n",
       "20345  ProviderId_4   ProductId_6  financial_services  ChannelId_2     50   \n",
       "\n",
       "      TransactionStartTime  PricingStrategy  FraudResult  \n",
       "41492  2018-12-26 18:45:43                2            0  \n",
       "4676   2018-11-20 18:11:54                2            0  \n",
       "92856  2019-02-10 18:34:25                1            0  \n",
       "35109  2018-12-21 09:44:43                2            0  \n",
       "20345  2018-12-07 18:01:28                2            0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO List out variable types\n",
    "\n",
    "data_type_dict = {'numerical': num_col,\n",
    "                      'categorical': ob_col,\n",
    "                    }\n",
    "output_var = 'FraudResult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_pandas.Automater.Automater at 0x1a30262ac8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and fit Automater\n",
    "# This is the best part of this module, here it prepares the data for any machine learning model, neural nets\n",
    "# or other models.\n",
    "# let's see how it does that now\n",
    "auto = Automater(data_type_dict=data_type_dict, output_var=output_var)\n",
    "auto.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's now use the model to transform our dataset that we will use in the machine learning\n",
    "train_X, train_y = auto.fit_transform(x_train_)\n",
    "test_X, test_y = auto.transform(x_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((71746, 11), (1, 71746))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#right now we should be having data that is already pre-formatted to be used in our models\n",
    "pd.DataFrame(train_X).T.shape,pd.DataFrame(train_y).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 71746)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_y).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71746,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_y).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Run\n",
    "\n",
    "Let's take this bad boy for a test run with a neural network.\n",
    "We are going to keep it simple so we can see how it does, in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets try this in a simple neural net\n",
    "\n",
    "from keras import Model\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = auto.input_nub\n",
    "x = Dense(128)(x)\n",
    "x = Dense(64)(x)\n",
    "x = Dense(32)(x)\n",
    "x = Dense(32)(x)\n",
    "x = auto.output_nub(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=auto.input_layers, outputs=x)\n",
    "model.compile(optimizer='adam', loss=auto.suggest_loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "71746/71746 [==============================] - 151s 2ms/step - loss: 0.4436\n",
      "Epoch 2/10\n",
      "71746/71746 [==============================] - 145s 2ms/step - loss: 0.4277\n",
      "Epoch 3/10\n",
      "71746/71746 [==============================] - 147s 2ms/step - loss: 0.3661\n",
      "Epoch 4/10\n",
      "68032/71746 [===========================>..] - ETA: 7s - loss: 0.3123"
     ]
    }
   ],
   "source": [
    "model.fit(train_X, train_y,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23916/23916 [==============================] - 1s 31us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9895799511610255"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test_y = model.predict(test_X)\n",
    "auto.inverse_transform_output(pred_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO List out variable types\n",
    "\n",
    "data_type_dict_ = {'numerical': ['Value', 'TransactionStartTime', 'PricingStrategy'],\n",
    "                      'categorical': ob_col,\n",
    "                    }\n",
    "output_var = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ = Automater(data_type_dict=data_type_dict_, output_var=output_var)\n",
    "test = auto_.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's now build random base models and check how they are doing\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\n",
    "from sklearn.svm import NuSVC,SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier,RadiusNeighborsClassifier\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's initialize the modles here\n",
    "sgd = SGDClassifier()\n",
    "rdm = RadiusNeighborsClassifier()\n",
    "ada = AdaBoostClassifier()\n",
    "grd = GradientBoostingClassifier()\n",
    "nsv = NuSVC()\n",
    "svc = SVC()\n",
    "knn = KNeighborsClassifier()\n",
    "rnc = RadiusNeighborsClassifier()\n",
    "xgb = XGBClassifier()\n",
    "rdmf = RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdmf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "'SGDClassifier':sgd,\n",
    "'RadiusNeighborsClassifier':rdm,\n",
    "'AdaBoostClassifier':ada,\n",
    "'GradientBoostingClassifier':grd,\n",
    "'NuSVC':nsv,\n",
    "'SVC':svc,\n",
    "'KNeighborsClassifier':knn,\n",
    "'RadiusNeighborsClassifier':rnc,\n",
    "'XGBClassifier':xgb\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am having a hard time in converting the data that I have into a fomat that can be accepted by the models above, We have managed to make it work with the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now that we have the a data structure let's loop through the structure and fit our data\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#result dataframe\n",
    "result = pd.DataFrame()\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    #let's fit the model\n",
    "    model.fit(pd.DataFrame(train_X).T, pd.Series(train_y).T)\n",
    "    \n",
    "    #let's pred on the test data\n",
    "    pred = model.predict(pd.DataFrame(test_X).T)\n",
    "    \n",
    "    #score the \n",
    "    score = f1_score(pd.Series(test_y),pred)\n",
    "    \n",
    "    #lets add this to a dataframe\n",
    "    result[model_name]=score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What have I learnt:\n",
    "\n",
    "1- We may need to do the initial data analysis but not as intensely as we used to before. Because in the end I need to know which columns are going to fall off or what\n",
    "\n",
    "2- We need to be able to handle data in different dimensions and data types, ndarrays, dataframes, dictionaries and others, because when it comes to the time of fitting this data into normal models it takes accuracy in those areas for you not to waste time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
